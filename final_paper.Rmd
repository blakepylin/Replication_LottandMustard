---
title: "Lott and Mustard Replication"
author: "Pin-Yun(Blake) Lin"
date: "5/13/2022"
header-includes:
  - \usepackage{placeins}
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(haven)
library(tidyverse)
library(data.table)
library(fixest)
library(bacondecomp) 
library(TwoWayFEWeights)
library(fixest)
library(glue)
library(did)
library(data.table)
library(fixest)
library(caret)
library(tidyverse)
library(ggplot2)
library(glmnet)
library(gbm)
library(ggmap)
library(rpart)
library(rpart.plot)
library(randomForest)
library(rsample)
library(modelr)
library(fastDummies)
library(scales)
library(here)
library(knitr)
library(kableExtra)
library(stargazer)
library(haven)
library(here)
library(foreach)

path <- here()

```
# Introduction
Civilian gun ownership has always been a center of debate in U.S. politics, and scholars have been working on related issues throughout history. This topic is also what Lott and Mustard were trying to answer in their paper “Crime, Deterrence, and Right-to-Carry Concealed Handguns”. They used the right-to-carry concealed gun law as the treatment to see its effect on 9 different types of crime, and the method they used was two-way fixed effect (TWFE). While TWFE is efficient and has been the default method for estimating difference-in-difference (DiD) with differential timing for years, it is not capable of handling treatments that are rolled out. Therefore, in this replication, we will try to solve two problems from the original Lott and Mustard paper. First, substitute county-level data with state-level data since the laws are implemented on a state level. Second, use alternative approaches that compensate for the downside of TWFE, the methods we would be using are proposed by Callaway & Sant’Anna, Goodman-Bacon, and Sun & Abraham.

# Background and Economic Theory
In the original paper, the authors were trying to know by allowing concealed handguns, will the law-abiding citizen be more likely to hurt each other, or the threat of others carrying concealed weapons deter crime? In order to answer this question, they used the panel data for U.S counties from 1997 to 1992 and analyzed the data with two-way fixed effects model (TWFE). The outcome variable: crime they were using includes 9 different categories, the FBI crime reports include seven categories of crime: murder, rape, aggravated assault, robbery, auto theft, burglary, and larceny. Two additional summary categories were included: violent crimes (including murder, rape, aggravated assault, and robbery) and property crimes (including auto theft, burglary, and larceny). By using TWFE, they found out that allowing citizens to carry concealed weapons deters violent crimes and it appears to produce no increase in accidental deaths. Because of this law implementation rollout, our treatment is assigned with differential timing, meaning that a state might be part of the untreated group in one year and part of the treated group in another year. This treatment rollout is summarized in Table 1.

\vspace{-5truemm}
```{r table 1, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
state_crime = read.csv("data/UpdatedStateLevelData-2010.csv")

state_rollout = state_crime %>% 
  filter(year>=1977 & year<=1992)

treat_table = state_rollout %>% 
  group_by(state) %>% 
  summarize(cnt = sum(shalll)) %>% 
  na.omit()

state_rollout = left_join(state_rollout, treat_table, by = c("state" = "state")) 

state_rollout = state_rollout %>% 
  mutate(treat_year = ifelse(cnt == 16, 'pre 1977', ifelse(cnt <= 16 & cnt > 0, 1992 - (cnt - 1), 0)))

state_rollout = state_rollout %>% 
  mutate(pre_treat = ifelse(treat_year == 'pre 1977',1,0))

rollout = state_rollout %>%
  distinct(state, treat_year) %>% 
  arrange(treat_year)

pre_1977 = rollout %>% 
  filter(treat_year == 'pre 1977')

post_1977 = rollout %>% 
  filter(treat_year != 'pre 1977') %>% 
  filter(treat_year != 0)

rollout_table = rbind(pre_1977, post_1977)
kbl(rollout_table, col.names = c("State", "Year"), caption = "Right-to-Carry Rollout", position = "h")
```
\FloatBarrier
# Data
In the panel data set, the right-to-carry law is coded 1 when the state has implemented the law, and 0 otherwise. While the authors used county-level data in the original paper, here we will be using state-level data since the right-to-carry laws are implemented at a state level, and it is noted that the county-level data have substantial measurement errors.  

The below table (table 2) shows the average arrest rate and its standard deviation for each type of crime, this number is calculated by using the average across states and years. We can see that Murder has the highest arrest rate at 91.3% followed by Aggravated Assault, Violent Crime, and Rape at around 40%, while auto theft is at the lowest at 13%. From this statistic, we can understand the focus of law enforcement is mainly on felony and serious crimes.

\vspace{-5truemm}
```{r table 2 arrests, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
# Table 2 Arrest Rates
arrest_select = state_crime %>% 
  select(state, year, aovio, aopro, aomur, aorap, aoaga, aorob, aobur, aolar, aoaut)
namies = c("Violent Crime", "Property Crime", "Murder", "Rape", "Aggravated Assault", "Robbery","Auto Theft", "Burglary", "Larceny")
sum_tab_sd = arrest_select %>% 
  select(year, aovio, aopro, aomur, aorap, aoaga, aorob, aobur, aolar, aoaut) %>%
  filter(year >= 1977 & year <= 1992) %>% 
  select(-year) %>% 
  summarise_all(sd, na.rm = TRUE) %>%
  round(2) %>% 
  t()
sum_tab_mean = arrest_select %>% 
  select(year, aovio, aopro, aomur, aorap, aoaga, aorob, aobur, aolar, aoaut) %>%
  filter(year >= 1977 & year <= 1992) %>% 
  select(-year) %>% 
  summarise_all(mean, na.rm = TRUE) %>% 
  round(2) %>% 
  t() %>% 
  cbind(sum_tab_sd)
row.names(sum_tab_mean) = namies
kbl(sum_tab_mean, col.names = c("Mean", "Sd"), caption = "Arrest Statistics", position = "h")
```
\FloatBarrier

\newpage
Table 3 here shows the average and standard deviation of the frequency of the crime outcomes per 100,000 people by using the average across states and years. We can see that the frequency decreases when the egregiousness of the crime increases, with murder and rape being the most infrequent crimes. There might be two possible reasons for this outcome, one is that people are just less likely to commit this kind of crime, and the second is that the high arrest rate as shown in table 2 serves as a form of deterrence to these egregious crimes.

```{r table 2 crimes, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
# Table 2 Crime Rates
Lott_select = state_crime %>% 
  select(state, year, ratvio, ratpro, ratmur, ratrap, rataga, ratrob, rataut, ratbur, ratlar)
namies = c("Violent Crime", "Property Crime", "Murder", "Rape", "Aggravated Assault", "Robbery","Auto Theft", "Burglary", "Larceny")
sum_tab_sd = Lott_select %>% 
  select(year, ratvio, ratpro, ratmur, ratrap, rataga, ratrob, rataut, ratbur, ratlar) %>%
  filter(year >= 1977 & year <= 1992) %>% 
  select(-year) %>% 
  summarise_all(sd, na.rm = TRUE) %>%
  round(2) %>% 
  t()
sum_tab_mean = Lott_select %>% 
  select(year, ratvio, ratpro, ratmur, ratrap, rataga, ratrob, rataut, ratbur, ratlar) %>%
  filter(year >= 1977 & year <= 1992) %>% 
  select(-year) %>% 
  summarise_all(mean, na.rm = TRUE) %>% 
  round(2) %>% 
  t() %>% 
  cbind(sum_tab_sd)
row.names(sum_tab_mean) = namies
kbl(sum_tab_mean, col.names = c("Mean", "Sd"), caption = "Crimes per 100,000", position = "h")
```
\FloatBarrier

<!-- \newpage -->

```{r twfe, message=FALSE, warning=FALSE, include=FALSE}
state_crime = read.csv("data/UpdatedStateLevelData-2010.csv")

# filter for replication
state_crime = state_crime %>% 
  filter(year>=1977 & year<=1992)

# Let's create a more user-friendly indicator of which states received treatment

state_crime = state_crime %>% 
  group_by(state) %>% 
  mutate(treat = ifelse(min(shalll) ==  1, 1, (ifelse(min(shalll) == max(shalll), 0, 1))))

treat_table = state_crime %>% 
  group_by(state) %>% 
  summarize(cnt = sum(shalll)) %>% 
  na.omit()

state_crime = left_join(state_crime, treat_table, by = c("state" = "state")) 

state_crime = state_crime %>% 
  mutate(treat_year = ifelse(cnt <= 16 & cnt > 0, 1992 - (cnt - 1), 0)) 

state_crime = state_crime %>% 
  select(treat_year, everything())

state_crime = state_crime %>% 
  mutate(time_to_treat = ifelse(treat_year == 0, 0,year - treat_year))

state_crime = state_crime %>% 
  select(time_to_treat, everything())

sapply(state_crime, function(x) sum(is.na(x)))

# aovio, aopro, aomur, aorap, aoaga, aorob, aobur, aolar, aoaut

outcomes <- c("lvio", "lpro", "lmur", "lrap", "laga", "lrob", "lbur", "llar", "laut")
Y <- length(outcomes)
acontrols <- c("aovio", "aopro", "aomur", "aorap", "aoaga", "aorob", "aobur", "aolar", "aoaut")

foreach(y = 1:Y) %do% {
  # index outcome
  yval <- outcomes[y]
  acon <- acontrols[y]
  fixed <- "| state + year"
  
  # formula for index outcome
  twfe_spec <- as.formula(paste0(yval, " ~ shalll + density + 
                               rpcpi + rpcim + rpcui + rpcrpo + 
                               ppwm1019 + ppwm2029 + ppwm3039 + 
                               ppwm4049 + ppwm5064 + ppwf1019 + 
                               ppwf2029 + ppwf3039 + ppwf4049 + 
                               ppwf5064 + ppbm1019 + ppbm2029 + 
                               ppbm3039 + ppbm4049 + ppbm5064 + 
                               ppbf1019 + ppbf2029 + ppbf3039 + 
                               ppbf4049 + ppbf5064 +ppnm1019 + 
                               ppnm2029 + ppnm3039 + ppnm4049 + 
                               ppnm5064 + ppnf1019 + ppnf1019 + 
                               ppnf2029 + ppnf3039 + ppnf4049 + 
                               ppnf5064 + ", acon, fixed))
  
  # twfe model spec using formula
  twfe_model <-  feols(fml = twfe_spec, 
                     data = state_crime)
  
  # assign model name according to index outcome
  mod_name <- paste("twfe", yval, sep = "_")
  assign(mod_name, twfe_model)
  
  # save model to model folder
  fname_mod <- paste0(mod_name, ".RDs")
  save(file = file.path(path, 'output', 'models', fname_mod), list = "twfe_model")
}

```


```{r calloway santana, message=FALSE, warning=FALSE, include=FALSE}
# callaway sant'ana

foreach(y = 1:Y) %do% {
  yval <- outcomes[y]
  x <- acontrols[y]
  
  rhs <- as.formula(paste('~ + ', x))
  atts <- att_gt(yname = yval, # LHS variable
                 tname = 'year', # panel time variable
                 idname = 'fipsstat', # firms' panel id variable
                 gname = 'treat_year', 
                 data = state_crime, # data
                 xformla = rhs,
                 est_method = "dr",
                 control_group = "notyettreated",
                 bstrap = TRUE, # if TRUE compute bootstrapped SE
                 biters = 1000, # number of bootstrap iterations
                 print_details = FALSE, # if TRUE, print detailed results
                 clustervars = 'fipsstat', # cluster level
                 panel = TRUE)
  
  cs_model <- aggte(atts, type = "group", balance_e = TRUE, na.rm = TRUE)
  
  cs_name <- paste("CS", yval, sep = "_")
  assign(cs_name, cs_model)
  
  # save model to model folder
  fname_mod <- paste0(cs_name, ".RDs")
  save(file = file.path(path, 'output', 'models', fname_mod), list = "cs_model")
}
```
\FloatBarrier
\newpage
# Empirical Model and Estimation
## Bacon Decomposition

Two-way Fixed Effects (TWFE) is the standard Difference-in-Differences estimation method. However, its efficacy is limited to situations when treatment occurs simultaneously. Since our data set contains multiple time periods and variations in treatment timing - the laws were implemented in different years across states. Here we would try using Bacon decomposition to solve the problem of using late-treated units compared to early-treated units. By using the binary treatment variable, we will re-estimate the effect of the right-to-carry law on different types of crime by coding a state as “treated” if at any time of that year the law had been implemented. For simplicity of modeling and interpretation, treatment will be the only variable on the right-hand side, we would not control for other covariates. 

To focus on the degree of pollution of the TWFE, we only report the weight and estimate of early to late 2x2s and late to early 2x2s. We can see from the chart (Table 5)that late to early 2x2s take account of 0.24 of the TWFE estimate, the influence of later to early treated in the mix is rather large. This is an important finding since the late to early 2x2s are estimated based on counter-factual data. Except for property and robbery crime, the average estimate for the late to early 2x2s has a lower estimate than the early to late 2x2s, this means that the TWFE is being pulled down by the late to early group, this is a crucial drawback in Lott and Mustard’s original modeling, as it could incorrectly prove the effectiveness of the law.

The table below is showing the weight and estimates of each type of crime:

\FloatBarrier
```{r mmmm bacon, message=FALSE, warning=FALSE, include=FALSE}
#bacon decomp

outcomes <- c("lvio", "lpro", "lmur", "lrap", "laga", "lrob", "lbur", "llar", "laut")
Y <- length(outcomes)

#bacon decomp
foreach(y = 1:Y) %do% {
# index outcome
  yval <- outcomes[y]
  
# formula for index outcome
  bacon_formula <- as.formula(paste(yval, "shalll", sep = "~"))
  
# specify bacon decomp
# wrangle full df of 2x2s into summary table by type
  bacon_decomp = bacon(bacon_formula, 
                       data = state_crime, 
                       id_var = "fipsstat", 
                       time_var = "year") %>% 
    group_by(type) %>% 
    summarise(avg_est = round(weighted.mean(estimate, weight), 3), 
              weight = sum(round(weight,3)))
  
  # assign decomp based on index
  bacon_name <- paste("bacon", yval, sep = "_")
  assign(bacon_name, bacon_decomp)
  
  # save model to model folder
  fname_mod <- paste0(bacon_name, ".RDs")
  save(file = file.path(path, 'output', 'models', fname_mod), list = "bacon_decomp")
}

```

```{r canadian bacon, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
Y <- length(outcomes)
beercan = foreach(y = 1:Y, .combine = rbind) %do% {
  yval <- outcomes[y]
  
  bacon_name = paste("bacon", yval, sep="_")
  fname_bacon = paste0(bacon_name, ".RDs")
  
  load(file.path(here(), "output", "models", fname_bacon))
  
  estimates = c(yval, bacon_decomp[1,])
  estimates2 = c(yval, bacon_decomp[3,])
  
  rbind(estimates, estimates2)
} %>% 
  data.frame()

colnames(beercan) = c("Treated_Variable_(Log)", "Type", "Average_Estimate", "Weight")

rownames(beercan) = NULL

beercan = beercan %>% 
  mutate(`Treated_Variable_(Log)` = ifelse(row_number()%%2 == 0, "", c("Rate of Violent Crime", "Murder Rate", "Aggravated Assault Rate", "Burglary Rate", "Auto Crime Rate", "Property Crime Rate", "Rape Rate", "Robbery Rate", "Larceny Rate")))

beercan_table = stargazer(beercan, 
                          type = "latex", 
                          summary = FALSE, 
                          rownames = FALSE,
                          header = FALSE,
                          title = "Bacon Decomposition Summary")
```
\newpage
## Twoway Fixed Effects vs Callaway-Sant'anna

Now, we would try using the Callaway-Sant’anna (CS) method to avoid the problem of late-to-early comparison by only using the never or not-yet treated as controls group through subsetting dataset. This method would split the observations into cohorts based on the time of the treatment, the model of this approach is shown below: 

  $$
  ATT_{(g,t)} = E[(\frac{G_g}{E[G_g]} - \frac{\frac{\hat{p}(X)C}{1-\hat{p}(X)}}{E[\frac{\hat{p}(X)C}{1-\hat{p}(X)}]})(Y_t - Y_{g-1})]
  $$

We can see that in all of the groups except the auto theft crime rate, TWFE overestimated the treatment effect by magnitude, in some of the cases (rape, aggravated assault, and robbery) the sign even flipped. By using the CS estimation, we could see that the treatment did not have that much effect as a deterrence to crime, and in the sign flipped cases, the law might actually increase the crime rate. The largest reduction of overestimation is rape at 7% of reduction, followed by aggravated assault, and robbery at around 5.5%.

The following table compares the TWFE model to CS in capturing the effect of the right-to-carry law treatment on the crime rate: 

```{r agg_DND_table, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
outcomes <- c("lvio", "lpro", "lmur", "lrap", "laga", "lrob", "lbur", "llar", "laut")
acontrols <- c("aovio", "aopro", "aomur", "aorap", "aoaga", "aorob", "aobur", "aolar", "aoaut")
Y <- length(outcomes)

effects <- foreach(y = 1:Y, .combine = rbind) %do% {
  # point to outcome index
  yval = outcomes[y]
  
  # make model strings in order to load
  twfe_name <- paste("twfe", yval, sep = "_")
  fname_twfe <- paste0(twfe_name, ".RDs")
  
  cs_name <- paste("CS", yval, sep = "_")
  fname_cs <- paste0(cs_name, ".RDs")
  
  # laod models into envi 
  # they will load as what they were named in the envi when saved
  load(file.path(path, 'output', 'models', fname_twfe))
  load(file.path(path, 'output', 'models', fname_cs))
  
  # access estimates, se, tvals, and pvals from each model
  estimates <- c(yval, twfe_model[["coefficients"]][["shalll"]], cs_model[["overall.att"]])
  se <- c(yval, twfe_model[["se"]][["shalll"]], cs_model[["overall.se"]])
  p <- c(yval, twfe_model[["coeftable"]][["Pr(>|t|)"]][1], cs_model[["overall.se"]])
  
  rbind(estimates, se)
} %>% 
  as.data.frame()


# doctor up the effecs a lil bit
L <- length(effects$V1)
colnames(effects) <- c("outcome", "TWFE", "CallawaySantAnna")
rownames(effects) <- NULL
effects$TWFE <- round(as.numeric(effects$TWFE), 3)
effects$CallawaySantAnna <- round(as.numeric(effects$CallawaySantAnna), 3)
effects$TWFE <- as.character(effects$TWFE)
effects$CallawaySantAnna <- as.character(effects$CallawaySantAnna)

# effects <- effects %>% 
#   mutate("Target Variable" = ifelse(row_number()%%2 == 0, "", c("Violent Crime Rate","Property Crime Rate","Murder Rate",  "Rape Rate","Aggravated Assault Rate","Robbery Rate", "Burglary Rate", "Larceny Rate", "Auto Crime Rate"))) %>% 
#   mutate(TWFE = ifelse(row_number()%%2 == 0, paste0("(", TWFE, ")"), TWFE), 
#          CallawaySantAnna = ifelse(row_number()%%2 == 0, paste0("(", CallawaySantAnna, ")"), CallawaySantAnna))
# c("Violent Crime Rate","Violent SE", "Property Crime Rate", "Property SE", "Murder Rate", "Murder SE", "Rape Rate", "Rape SE", "Aggravated Assault Rate", "AggAssault SE", "Robbery Rate", "Robbery SE", "Burglary Rate", "Burglary SE", "Larceny Rate", "Larceny SE", "Auto Crime Rate", "Auto SE")

effects <- effects %>% 
  mutate("Target Variable" = c("Violent Crime Rate","", "Property Crime Rate", "", "Murder Rate", "", "Rape Rate", "", "Aggravated Assault Rate", "", "Robbery Rate", "", "Burglary Rate", "", "Larceny Rate", "", "Auto Crime Rate", "")) %>% 
  mutate(TWFE = ifelse(row_number()%%2 == 0, paste0("(", TWFE, ")"), TWFE), 
         CallawaySantAnna = ifelse(row_number()%%2 == 0, paste0("(", CallawaySantAnna, ")"), CallawaySantAnna))

#making a table 

effects_table = stargazer(effects,
                          type= "latex",
                          summary = FALSE,
                          rownames = FALSE,
                          header = FALSE,
                          title = "TWFE and CS Comparison")
```



\FloatBarrier
```{r sun abraham, message=FALSE, warning=FALSE, include=FALSE}
foreach(y = 1:Y) %do% {
# index outcome
yval <- outcomes[y]
acon <- acontrols[y]

# formula for index outcome
sa_spec <- as.formula(paste0(yval, "~ sunab(treat_year, year) + density + 
                             rpcpi + rpcim + rpcui + rpcrpo + 
                             ppwm1019 + ppwm2029 + ppwm3039 + 
                             ppwm4049 + ppwm5064 + ppwf1019 + 
                             ppwf2029 + ppwf3039 + ppwf4049 + 
                             ppwf5064 + ppbm1019 + ppbm2029 + 
                             ppbm3039 + ppbm4049 + ppbm5064 + 
                             ppbf1019 + ppbf2029 + ppbf3039 + 
                             ppbf4049 + ppbf5064 +ppnm1019 + 
                             ppnm2029 + ppnm3039 + ppnm4049 + 
                             ppnm5064 + ppnf1019 + ppnf1019 + 
                             ppnf2029 + ppnf3039 + ppnf4049 + 
                             ppnf5064 + ", acon))
# twfe model spec using formula
mod_SA <- feols(fml = sa_spec, 
                data = state_crime,
                subset = ~ year < 1992,
                vcov = ~ fipsstat + year)

# assign model name according to index outcome

mod_name <- paste("SA", yval, sep = "_")
assign(mod_name, mod_SA)

fname_mod <- paste0(mod_name, ".RDs")
save(file = file.path(path, 'output', 'models', fname_mod))

}
```

\newpage
## Event Study: Sun and Abraham
Lastly, we will use San & Abraham’s approach to solve the differential timing problem. This approach combines the weighted average feature from the Bacon decomposition and the Cohort grouping from Callaway Sant’Anna. This approach allows us to calculate an interaction-weighted estimator, which is more robust in estimating dynamic treatment effects with TWFE under heterogeneity and differential timing, plus we can see the leads and lags by using their model.

The nine graphs below are showing the Event Study plots for the dynamic treatment effect on each crime, each dots represent the estimated treatment effect at that time and the vertical line is the 95% confidence interval of the estimate. From the graphs, we can see that the parallel trends barely holds, and the estimate for many crime are not significant at a 95% level, we cannot clearly see the effect of the implementation of the law.



\FloatBarrier
```{r SA Plots, echo=FALSE, message=FALSE, warning=FALSE}

iplot(SA_lvio,sep =.5,ref.line = -1,
      xlab = 'Time to treatment',
      main = 'Staggered treatment: Violent Crime')

iplot(SA_lpro,sep =.5,ref.line = -1,
      xlab = 'Time to treatment',
      main = 'Staggered treatment: Property Crime')

iplot(SA_lmur,sep =.5,ref.line = -1,
      xlab = 'Time to treatment',
      main = 'Staggered treatment: Murder')

iplot(SA_lrap,sep =.5,ref.line = -1,
      xlab = 'Time to treatment',
      main = 'Staggered treatment: Rape')

iplot(SA_laga,sep =.5,ref.line = -1,
      xlab = 'Time to treatment',
      main = 'Staggered treatment: Aggravated Assault')

iplot(SA_lrob,sep =.5,ref.line = -1,
      xlab = 'Time to treatment',
      main = 'Staggered treatment: Robbery')
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}

iplot(SA_lbur,sep =.5,ref.line = -1,
      xlab = 'Time to treatment',
      main = 'Staggered treatment: Burglary')

iplot(SA_llar,sep =.5,ref.line = -1,
      xlab = 'Time to treatment',
      main = 'Staggered treatment: Larceny')

iplot(SA_laut,sep =.5,ref.line = -1,
      xlab = 'Time to treatment',
      main = 'Staggered treatment: Auto Theft')
```

\newpage
# Conclusion
After applying the modern approaches of DiD, we estimated some results that diverge from the original paper. In some extreme cases, the effect of the right-to-carry law might even have the opposite effect as the authors originally estimated. Although using state-level data with modern approaches could help us understand the true effect of treatment better, there is still some downside of DiD approach in general, one underlying assumption of these models is that all the treatment groups received the same profile of treatment (or the same treatment at a specific time), this assumption failed to capture the difference among states, and affect the information that our estimate is conveying. Another problem is that DiD estimator provides unbiased treatment only when the parallel trends assumption exists, which is rarely the case in a real-world scenario. Some alternatives to DiD might be looking into: synthetic control, a lagged dependent variable (LDV) regression approach and matching on past outcomes.

